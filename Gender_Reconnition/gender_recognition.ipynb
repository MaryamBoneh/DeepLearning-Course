{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gender-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSNpXSpkdpP3"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rVTO3ylktzC"
      },
      "source": [
        "!pip3 install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBsT9h-1d5dt",
        "outputId": "818f92de-3295-421e-e2c2-19bcce12285d"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJITp9QhfIYo",
        "outputId": "4101846f-9132-4a1d-f2f3-4f9595524c53"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/gender-recognition-200k-images-celeba"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading gender-recognition-200k-images-celeba.zip to /content\n",
            "100% 1.31G/1.32G [00:24<00:00, 95.7MB/s]\n",
            "100% 1.32G/1.32G [00:24<00:00, 56.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVnwpVK8g6IV"
      },
      "source": [
        "!unzip -qq gender-recognition-200k-images-celeba.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4UvYHeSja0E"
      },
      "source": [
        "import wandb\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from wandb.keras import WandbCallback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D, Flatten, BatchNormalization, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjt7f37WeJo0"
      },
      "source": [
        "wandb.init(project='gender-recognition')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCB1QV0mlto0"
      },
      "source": [
        "batch_size = 256\n",
        "lr = 0.001\n",
        "epoch = 40\n",
        "width = height = 64"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92cGa_ztkvDB",
        "outputId": "6f862afd-4ece-4c25-8258-b5628e4ddf54"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "                                  rescale = 1 / 255,\n",
        "                                  horizontal_flip = True\n",
        "                                  )\n",
        "\n",
        "train_data = data_generator.flow_from_directory(\"Dataset/Train/\",\n",
        "                                                    target_size = (width, height),\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    shuffle = True\n",
        "                                                    )\n",
        "\n",
        "val_data = data_generator.flow_from_directory(\"Dataset/Validation/\",\n",
        "                                                    target_size = (width, height),\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    shuffle = True\n",
        "                                                    )\n",
        "\n",
        "test_data = data_generator.flow_from_directory(\"Dataset/Test/\",\n",
        "                                                    target_size = (width, height),\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = batch_size,\n",
        "                                                    shuffle = True\n",
        "                                                    )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160000 images belonging to 2 classes.\n",
            "Found 22598 images belonging to 2 classes.\n",
            "Found 20001 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4yiM0adnSFP"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    Conv2D(96, (11, 11), activation= 'relu', input_shape = (width, height, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2),\n",
        "\n",
        "\n",
        "    Conv2D(256, (11, 11), strides=(1, 1), activation= 'relu', padding= 'same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "\n",
        "    Conv2D(384, (3, 3), strides=(1, 1), activation= 'relu', padding= 'same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "\n",
        "    Conv2D(384, (3, 3), strides=(1, 1), activation= 'relu', padding= 'same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "\n",
        "    Conv2D(256, (3, 3), strides=(1, 1), activation= 'relu', padding= 'same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, strides= (2, 2)),\n",
        "\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "\n",
        "    Dense(4096, activation= 'relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "\n",
        "    Dense(4096, activation= 'relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "\n",
        "    Dense(1, activation='sigmoid')                          \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXmcSwigCitO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a396b1df-71f7-47b7-afb5-55d1aba58609"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50V2(\n",
        "    input_shape=(width, height, 3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling = 'max'\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "94683136/94668760 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxr5_GmKDxKb"
      },
      "source": [
        "for layer in base_model.layers[:-8]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu1YUukrD0jn"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    base_model,\n",
        "    Dense(2, activation='softmax')                          \n",
        "])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLwF7CtRfTu5"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.SGD(),\n",
        "              loss = tf.keras.losses.categorical_crossentropy,\n",
        "              metrics='accuracy')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUXx9JHetmr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e2e10d1-0cb0-4070-d1c8-44a7ca5e7ba4"
      },
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch = train_data.samples / batch_size,\n",
        "          validation_data = val_data,\n",
        "          validation_steps = val_data.samples / batch_size,\n",
        "          epochs = 10,\n",
        "          callbacks = [WandbCallback()]\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 258s 353ms/step - loss: 0.3551 - accuracy: 0.8458 - val_loss: 0.3035 - val_accuracy: 0.8684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "625/625 [==============================] - 218s 349ms/step - loss: 0.2841 - accuracy: 0.8783 - val_loss: 0.3137 - val_accuracy: 0.8686\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 217s 347ms/step - loss: 0.2628 - accuracy: 0.8880 - val_loss: 0.2997 - val_accuracy: 0.8707\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 217s 347ms/step - loss: 0.2457 - accuracy: 0.8973 - val_loss: 0.2861 - val_accuracy: 0.8790\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 215s 344ms/step - loss: 0.2302 - accuracy: 0.9044 - val_loss: 0.2788 - val_accuracy: 0.8827\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 215s 343ms/step - loss: 0.2153 - accuracy: 0.9115 - val_loss: 0.2884 - val_accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 214s 342ms/step - loss: 0.2027 - accuracy: 0.9174 - val_loss: 0.2871 - val_accuracy: 0.8831\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 213s 341ms/step - loss: 0.1855 - accuracy: 0.9254 - val_loss: 0.3055 - val_accuracy: 0.8765\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 213s 341ms/step - loss: 0.1737 - accuracy: 0.9310 - val_loss: 0.3504 - val_accuracy: 0.8651\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 213s 340ms/step - loss: 0.1584 - accuracy: 0.9375 - val_loss: 0.3308 - val_accuracy: 0.8702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f68e90410>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIO1BHg0fNLU"
      },
      "source": [
        "model.save('/content/drive/MyDrive/gender_model_resnet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgDmqAIWhFK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1530c1-4941-4d9f-bb3c-7013c21a63f1"
      },
      "source": [
        "Y_pred = model.predict(test_data)\n",
        "y_pred = np.argmax(Y_pred, axis= 1)\n",
        "\n",
        "print(confusion_matrix(test_data.classes, y_pred))\n",
        "targets = set(test_data.class_indices.keys())\n",
        "print('classification_report:')\n",
        "print(classification_report(test_data.classes, y_pred, target_names= targets))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6374 5168]\n",
            " [4716 3743]]\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Female       0.57      0.55      0.56     11542\n",
            "        Male       0.42      0.44      0.43      8459\n",
            "\n",
            "    accuracy                           0.51     20001\n",
            "   macro avg       0.50      0.50      0.50     20001\n",
            "weighted avg       0.51      0.51      0.51     20001\n",
            "\n"
          ]
        }
      ]
    }
  ]
}