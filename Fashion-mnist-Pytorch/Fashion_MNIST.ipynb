{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion-MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "ex_y8VnZBhm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktwrEJluan72"
      },
      "source": [
        "import torch, torchvision, wandb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¸wandb config"
      ],
      "metadata": {
        "id": "GHVk7hVGSr41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {\n",
        "            \"learning_rate\": 0.001,\n",
        "            \"epochs\": 20,\n",
        "            \"batch_size\": 64,\n",
        "           }\n",
        "\n",
        "wandb.init(project=\"Fashion-MNIST-by-Torch\", config=configs)\n",
        "config = wandb.config\n"
      ],
      "metadata": {
        "id": "52uLIDiTCDDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¸Class"
      ],
      "metadata": {
        "id": "doaPy7DdSySn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXMzd2qDawlp"
      },
      "source": [
        "class mnist_classifire(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.L1=torch.nn.Linear(784,256)\n",
        "        self.L2=torch.nn.Linear(256,64)\n",
        "        self.L3=torch.nn.Linear(64,10)\n",
        "        # self.L4=torch.nn.Linear(128,10)\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.reshape((x.shape[0],784))\n",
        "\n",
        "        z = self.L1(x)\n",
        "        z = torch.relu(z)\n",
        "        z = torch.dropout(z,0.2,train = True)\n",
        "\n",
        "        z = self.L2(z)\n",
        "        z = torch.relu(z)\n",
        "        z = torch.dropout(z,0.2,train = True)\n",
        "        z = self.L3(z)\n",
        "        z = torch.relu(z)\n",
        "        z = torch.dropout(z,0.2,train = True)\n",
        "\n",
        "        y = torch.softmax(z,dim = 1)\n",
        "        return y\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njHcZCkkcoJw",
        "outputId": "825a4522-14f1-4e93-c80f-5f49b664d7f7"
      },
      "source": [
        "device=torch.device(\"cuda\")\n",
        "model=mnist_classifire()\n",
        "model=model.to(device)\n",
        "model.train(True)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mnist_classifire(\n",
              "  (L1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (L2): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (L3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFcIKXlLd6eJ"
      },
      "source": [
        "batch=64\n",
        "epoch=20\n",
        "lr=0.001"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv3e0LcOeKu0"
      },
      "source": [
        "data_transform=torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(),\n",
        "     torchvision.transforms.Normalize((0),(1))]\n",
        ")\n",
        "dataset = torchvision.datasets.FashionMNIST(\"./dataset\",train=True,download=True,transform=data_transform)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvbYC94peue7"
      },
      "source": [
        "train_data = torch.utils.data.DataLoader(dataset,batch_size=batch,shuffle=True)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1sgzzzKgfCZ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
        "loss_func = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crJ2a5c8m97z"
      },
      "source": [
        "def cal_acc(y_hat,labels):\n",
        "    _,y_hat_max=torch.max(y_hat,1)\n",
        "    acc=torch.sum(y_hat_max==labels.data,dtype=torch.float64)/len(y_hat)\n",
        "    return acc\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¸Train"
      ],
      "metadata": {
        "id": "f4ZgZXurecbm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu_jPhbwk9BE",
        "outputId": "49cf81e4-8cd5-433e-9853-81a55f053007"
      },
      "source": [
        "for ep in range(epoch):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for im,labels in train_data:\n",
        "        im = im.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #forwarding\n",
        "        y_hat = model(im)\n",
        "\n",
        "        #backwarding\n",
        "        loss = loss_func(y_hat,labels)\n",
        "        loss.backward()\n",
        "\n",
        "        #update\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss\n",
        "        train_acc += cal_acc(y_hat,labels)\n",
        "\n",
        "    total_loss  =  train_loss/len(train_data)\n",
        "    total_acc  =  train_acc/len(train_data)\n",
        "\n",
        "    print(f\"epoch:{ep} , Loss:{total_loss} , accuracy: {total_acc}\")\n",
        "\n",
        "    wandb.log({'epochs': ep,\n",
        "      'train_acc': total_acc,\n",
        "      'train_loss': total_loss})"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0 , Loss:1.8520758152008057 , accuracy: 0.609391657782516\n",
            "epoch:1 , Loss:1.7961249351501465 , accuracy: 0.6577991737739872\n",
            "epoch:2 , Loss:1.785601019859314 , accuracy: 0.6678271588486141\n",
            "epoch:3 , Loss:1.781274676322937 , accuracy: 0.6716584488272921\n",
            "epoch:4 , Loss:1.781451940536499 , accuracy: 0.6718416844349681\n",
            "epoch:5 , Loss:1.77535080909729 , accuracy: 0.6779217750533049\n",
            "epoch:6 , Loss:1.7772291898727417 , accuracy: 0.6750233208955224\n",
            "epoch:7 , Loss:1.7766743898391724 , accuracy: 0.6744069829424307\n",
            "epoch:8 , Loss:1.7744252681732178 , accuracy: 0.6761727078891258\n",
            "epoch:9 , Loss:1.7696712017059326 , accuracy: 0.681586487206823\n",
            "epoch:10 , Loss:1.7722129821777344 , accuracy: 0.6781216684434968\n",
            "epoch:11 , Loss:1.77056086063385 , accuracy: 0.6800872867803838\n",
            "epoch:12 , Loss:1.7701897621154785 , accuracy: 0.6784215085287847\n",
            "epoch:13 , Loss:1.7701143026351929 , accuracy: 0.6805037313432836\n",
            "epoch:14 , Loss:1.7665692567825317 , accuracy: 0.6826525852878464\n",
            "epoch:15 , Loss:1.766517996788025 , accuracy: 0.6834521588486141\n",
            "epoch:16 , Loss:1.7684870958328247 , accuracy: 0.6801206023454157\n",
            "epoch:17 , Loss:1.7657493352890015 , accuracy: 0.6832522654584222\n",
            "epoch:18 , Loss:1.7661213874816895 , accuracy: 0.6833688699360341\n",
            "epoch:19 , Loss:1.7669243812561035 , accuracy: 0.6822694562899787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¸Save weights"
      ],
      "metadata": {
        "id": "thx4D3-weica"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td8o6472otgp"
      },
      "source": [
        "torch.save(model.state_dict(), \"fashion-mnist.pth\")"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dprT4WW8pxRj"
      },
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¸Inference"
      ],
      "metadata": {
        "id": "vFwufs4nepti"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbEbtfSCpE7Z",
        "outputId": "59c45bbd-90d9-4751-e0e7-bd02679fb4de"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "img=cv2.imread(\"shirt.png\")\n",
        "img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "img=cv2.resize(img,(28,28))\n",
        "tensor=data_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "y_hat=model(tensor)\n",
        "\n",
        "y_hat=y_hat.cpu().detach().numpy()\n",
        "output=np.argmax(y_hat)\n",
        "output"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    }
  ]
}